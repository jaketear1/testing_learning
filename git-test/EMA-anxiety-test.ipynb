{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sp\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import pearsonr\n",
    "import mne\n",
    "import pylsl\n",
    "import PyQt5\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from pylsl import StreamInfo, StreamOutlet, resolve_streams, StreamInlet\n",
    "import pandas as pd\n",
    "from mne import Annotations\n",
    "\n",
    "import fooof\n",
    "from fooof import FOOOF\n",
    "from fooof import FOOOFGroup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mne.time_frequency import psd_array_welch\n",
    "\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic testing with LSL Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream 1:\n",
      "  Name: Neuroeducation EEG\n",
      "  Type: EEG\n",
      "  Source ID: neuroEdu_psy-pdb-a403l\n",
      "  Channels: 19\n",
      "  Sampling Rate: 250.0 Hz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pylsl import resolve_streams\n",
    "\n",
    "# Find all available streams\n",
    "streams = resolve_streams()\n",
    "\n",
    "# Print details of each stream found\n",
    "for i, stream in enumerate(streams):\n",
    "    print(f\"Stream {i + 1}:\")\n",
    "    print(f\"  Name: {stream.name()}\")\n",
    "    print(f\"  Type: {stream.type()}\")\n",
    "    print(f\"  Source ID: {stream.source_id()}\")\n",
    "    print(f\"  Channels: {stream.channel_count()}\")\n",
    "    print(f\"  Sampling Rate: {stream.nominal_srate()} Hz\")\n",
    "    print()\n",
    "\n",
    "inlet = StreamInlet(streams[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread running\n"
     ]
    }
   ],
   "source": [
    "from PyQt5.QtCore import QThread\n",
    "class TestThread(QThread):\n",
    "    def run(self):\n",
    "        print(\"Thread running\")\n",
    "\n",
    "thread = TestThread()\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-29 15:57:36.690 (   2.695s) [         9BB933D]      netinterfaces.cpp:36    INFO| netif '{738A536F-0732-4218-A9BC-A6F85F1C31A5}' (status: 1, multicast: 1\n",
      "2025-08-29 15:57:36.691 (   2.695s) [         9BB933D]      netinterfaces.cpp:58    INFO| \tIPv6 ifindex 6\n",
      "2025-08-29 15:57:36.691 (   2.695s) [         9BB933D]      netinterfaces.cpp:36    INFO| netif '{74181DAB-17E6-4BE5-8CE9-A6B506C17701}' (status: 2, multicast: 1\n",
      "2025-08-29 15:57:36.691 (   2.695s) [         9BB933D]      netinterfaces.cpp:36    INFO| netif '{79B5D82F-E867-493A-A549-8D4FE77595C8}' (status: 2, multicast: 1\n",
      "2025-08-29 15:57:36.691 (   2.696s) [         9BB933D]      netinterfaces.cpp:36    INFO| netif '{A32C7133-760F-4795-BE45-5A3BAC0ADED1}' (status: 2, multicast: 1\n",
      "2025-08-29 15:57:36.691 (   2.696s) [         9BB933D]      netinterfaces.cpp:36    INFO| netif '{2403CA2A-4C78-4CBA-9D29-67AB797DC12F}' (status: 2, multicast: 1\n",
      "2025-08-29 15:57:36.692 (   2.696s) [         9BB933D]      netinterfaces.cpp:36    INFO| netif '{6EEA76A1-1CDE-43D6-9DB6-B7342BA5B4E2}' (status: 2, multicast: 1\n",
      "2025-08-29 15:57:36.692 (   2.696s) [         9BB933D]      netinterfaces.cpp:36    INFO| netif '{DA9C60E2-CF2A-11EF-AE7C-806E6F6E6963}' (status: 1, multicast: 1\n",
      "2025-08-29 15:57:36.693 (   2.697s) [         9BB933D]      netinterfaces.cpp:58    INFO| \tIPv6 ifindex 1\n",
      "2025-08-29 15:57:36.693 (   2.697s) [         9BB933D]         api_config.cpp:270   INFO| Loaded default config\n",
      "2025-08-29 15:57:37.707 (   3.712s) [         9BB933D]             common.cpp:65    INFO| git:6ca188c266c21f7228dc67077303fa6abaf2e8be/branch:refs/tags/v1.16.2/build:Release/compiler:MSVC-19.0.24245.0/link:SHARED\n",
      "c:\\Users\\jt25h\\AppData\\Local\\anaconda3\\envs\\testing_learning\\Lib\\site-packages\\IPython\\utils\\_process_win32.py:138: ResourceWarning: unclosed file <_io.BufferedWriter name=3>\n",
      "  res = process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\Users\\jt25h\\AppData\\Local\\anaconda3\\envs\\testing_learning\\Lib\\site-packages\\IPython\\utils\\_process_win32.py:138: ResourceWarning: unclosed file <_io.BufferedReader name=4>\n",
      "  res = process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\Users\\jt25h\\AppData\\Local\\anaconda3\\envs\\testing_learning\\Lib\\site-packages\\IPython\\utils\\_process_win32.py:138: ResourceWarning: unclosed file <_io.BufferedReader name=5>\n",
      "  res = process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%gui qt\n",
    "!python C:\\Users\\jt25h\\testing_learning\\App-SigVisualizer-master\\sigvisualizer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### something else --\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'resolve_stream' from 'pylsl' (c:\\Users\\jt25h\\AppData\\Local\\anaconda3\\envs\\testing_learning\\Lib\\site-packages\\pylsl\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpylsl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StreamInlet, resolve_stream\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Resolve and open the LSL stream\u001b[39;00m\n\u001b[32m      7\u001b[39m streams = resolve_stream()\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'resolve_stream' from 'pylsl' (c:\\Users\\jt25h\\AppData\\Local\\anaconda3\\envs\\testing_learning\\Lib\\site-packages\\pylsl\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from pylsl import StreamInlet, resolve_streams\n",
    "\n",
    "# Resolve and open the LSL stream\n",
    "streams = resolve_streams()\n",
    "inlet = StreamInlet(streams[0])\n",
    "\n",
    "# Parameters\n",
    "sampling_rate = 250  # samples per second\n",
    "window_length = 5    # seconds\n",
    "buffer_size = sampling_rate * window_length  # 1280 samples for 5 seconds at 256 Hz\n",
    "\n",
    "# Buffer for holding the last 5 seconds of data\n",
    "data_buffer = np.zeros(buffer_size)\n",
    "\n",
    "# Set up the plot\n",
    "start_time = time.time()\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "x = 0\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        time.sleep(max(0, 5.0 - elapsed_time))\n",
    "        # Pull samples for 1 second\n",
    "        new_data = []\n",
    "        for _ in range(buffer_size):  # 256 samples per second\n",
    "            sample, _ = inlet.pull_sample()\n",
    "            new_data.append(sample[0])  # Assuming single-channel data; adjust for multi-channel\n",
    "\n",
    "        # Update the buffer with new data, shifting older data out\n",
    "        data_buffer = np.roll(data_buffer, -buffer_size)\n",
    "        data_buffer[-buffer_size:] = np.array(new_data).flatten()\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        line, = ax.plot(data_buffer)\n",
    "        ax.set_ylim(-5000, 5000)  # Adjust y-axis limits as needed based on signal range\n",
    "        ax.set_title(\"Live EEG Data Stream\")\n",
    "        ax.set_xlabel(\"Samples\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        # Update the plot with the new buffer data\n",
    "        line.set_ydata(data_buffer)\n",
    "\n",
    "        ax.set_xlim(0, buffer_size)  # Adjust the x-axis range\n",
    "        plt.pause(0.001)  # Small pause to update the plot\n",
    "\n",
    "        # Maintain a 1-second loop interval\n",
    "        elapsed_time = time.time() - start_time\n",
    "        x = x+1\n",
    "        print(x)\n",
    "        \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Streaming stopped.\")\n",
    "\n",
    "# Close plot on exit\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing labrecorder / mne workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream 1:\n",
      "  Name: MarkerStream\n",
      "  Type: Markers\n",
      "  Source ID: \n",
      "  Channels: 1\n",
      "  Sampling Rate: 0.0 Hz\n",
      "\n",
      "Stream 2:\n",
      "  Name: Neuroeducation EEG\n",
      "  Type: EEG\n",
      "  Source ID: neuroEdu_JakeTear\n",
      "  Channels: 19\n",
      "  Sampling Rate: 250.0 Hz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = StreamInfo(name='MarkerStream', type='Markers', channel_count=1, nominal_srate=0, channel_format='string')\n",
    "outlet = StreamOutlet(info)\n",
    "\n",
    "# Find all available streams\n",
    "streams = resolve_stream()\n",
    "\n",
    "inlet = StreamInlet(streams[0])\n",
    "\n",
    "# Print details of each stream found\n",
    "for i, stream in enumerate(streams):\n",
    "    print(f\"Stream {i + 1}:\")\n",
    "    print(f\"  Name: {stream.name()}\")\n",
    "    print(f\"  Type: {stream.type()}\")\n",
    "    print(f\"  Source ID: {stream.source_id()}\")\n",
    "    print(f\"  Channels: {stream.channel_count()}\")\n",
    "    print(f\"  Sampling Rate: {stream.nominal_srate()} Hz\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending test markers to the marker stream...\n",
      "Sent: TestMarker_1\n",
      "Sent: TestMarker_2\n",
      "Sent: TestMarker_3\n",
      "Sent: TestMarker_4\n",
      "Sent: TestMarker_5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Send test markers\n",
    "print(\"Sending test markers to the marker stream...\")\n",
    "for i in range(5):\n",
    "    marker = f\"TestMarker_{i+1}\"\n",
    "    outlet.push_sample([marker])\n",
    "    print(f\"Sent: {marker}\")\n",
    "    time.sleep(1)  # Wait 1 second between markers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analysis part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream Name: MarkerStream\n",
      "Stream Type: Markers\n",
      "Markers in the Marker stream:\n",
      "  Marker: TestMarker_1 at 1299528.68601\n",
      "  Marker: TestMarker_2 at 1299529.68731\n",
      "  Marker: TestMarker_3 at 1299530.68843\n",
      "  Marker: TestMarker_4 at 1299531.68954\n",
      "  Marker: TestMarker_5 at 1299532.69020\n",
      "Stream Name: Neuroeducation EEG\n",
      "Stream Type: EEG\n"
     ]
    }
   ],
   "source": [
    "from pyxdf import load_xdf\n",
    "\n",
    "# Load the XDF file\n",
    "project_directory = os.path.dirname(os.path.abspath(\"EMA-anxiety-test\"))\n",
    "xdf_file = os.path.join(project_directory, \"EMAData\", \"Test1.xdf\")\n",
    "streams, header = load_xdf(xdf_file)\n",
    "\n",
    "\n",
    "# Print the streams and check for the marker stream\n",
    "for stream in streams:\n",
    "    print(f\"Stream Name: {stream['info']['name'][0]}\")\n",
    "    print(f\"Stream Type: {stream['info']['type'][0]}\")\n",
    "    if stream['info']['type'][0] == 'Markers':\n",
    "        print(\"Markers in the Marker stream:\")\n",
    "        for marker, timestamp in zip(stream['time_series'], stream['time_stamps']):\n",
    "            print(f\"  Marker: {marker[0]} at {timestamp:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-21.97799704 -31.03703751 -39.48874499 ... -47.20554681 -53.95637456\n",
      "  -59.65138355]\n",
      " [-49.09486563 -55.74706724 -61.24529353 ...  48.28789524  55.06057603\n",
      "   60.69349226]\n",
      " [-66.09546692 -68.77214688 -69.94518952 ... -49.34865272 -56.12996382\n",
      "  -61.68404671]\n",
      " ...\n",
      " [-68.49372204 -69.99948759 -68.6022431  ... -61.68542776 -67.10983657\n",
      "  -69.75107468]\n",
      " [-67.82217799 -62.78267962 -55.03672982 ...  62.37128763  67.58913404\n",
      "   69.89333146]\n",
      " [-53.17550142 -42.40621168 -29.73814478 ... -63.02925969 -68.02569638\n",
      "  -69.97621943]]\n",
      "250.0\n",
      "['Fp1', 'Fp2', 'F7', 'F8', 'F3', 'F4', 'T3', 'T4', 'C3', 'C4', 'T5', 'T6', 'P3', 'P4', 'O1', 'O2', 'Fz', 'Cz', 'Pz']\n",
      "Creating RawArray with float64 data, n_channels=19, n_times=2250\n",
      "    Range : 0 ... 2249 =      0.000 ...     8.996 secs\n",
      "Ready.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x19cccbded50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_directory = os.path.dirname(os.path.abspath(\"EMA-anxiety\"))\n",
    "\n",
    "streams, header = pyxdf.load_xdf(os.path.join(project_directory, r\"EMAData\", r\"Test1.xdf\"))\n",
    "eeg_stream = next((s for s in streams if s['info']['type'][0] == 'EEG'), None)\n",
    "eeg_data = np.array(eeg_stream['time_series']).T  # Transpose to channels x samples\n",
    "sfreq = float(eeg_stream['info']['nominal_srate'][0])  # Sampling frequency\n",
    "ch_names = eeg_stream['info']['desc'][0]['channels'][0]['channel']  # Channel names\n",
    "ch_names = [ch['label'][0] for ch in ch_names]\n",
    "\n",
    "print(eeg_data)\n",
    "print(sfreq)\n",
    "print(ch_names)\n",
    "\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
    "\n",
    "raw_eeg_data = mne.io.RawArray(eeg_data, info)\n",
    "raw_eeg_data.rename_channels({ch: ch.capitalize() for ch in raw_eeg_data.ch_names})\n",
    "    # Add standard montage (10-20 system)\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "raw_eeg_data.set_montage(montage)\n",
    "raw_eeg_data.plot(title=\"Resting State EEG (Eyes Closed)\", scalings='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x19cd083bad0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mne import Annotations\n",
    "\n",
    "marker_stream = next(s for s in streams if s['info']['type'][0] == 'Markers')\n",
    "\n",
    "markers = [m[0] for m in marker_stream['time_series']]\n",
    "marker_timestamps = marker_stream['time_stamps']\n",
    "\n",
    "\n",
    "# Align marker timestamps with the EEG recording\n",
    "annotations = Annotations(\n",
    "    onset=marker_timestamps - eeg_timestamps[0],  # Align to EEG start time\n",
    "    duration=[0] * len(marker_timestamps),       # Markers are instantaneous\n",
    "    description=markers                          # Marker descriptions\n",
    ")\n",
    "\n",
    "# Add annotations to the Raw object\n",
    "raw_eeg_data.set_annotations(annotations)\n",
    "\n",
    "raw_eeg_data.plot(title=\"Resting State EEG (Eyes Closed)\", scalings='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['TestMarker_1', 'TestMarker_2', 'TestMarker_3', 'TestMarker_4', 'TestMarker_5']\n",
      "Events: [[ 535    0    1]\n",
      " [ 785    0    2]\n",
      " [1036    0    3]\n",
      " [1286    0    4]\n",
      " [1536    0    5]]\n",
      "Event IDs: {'TestMarker_1': 1, 'TestMarker_2': 2, 'TestMarker_3': 3, 'TestMarker_4': 4, 'TestMarker_5': 5}\n",
      "Not setting metadata\n",
      "5 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 5 events and 126 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x19cd08e2210>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Dropped 0 epochs: \n",
      "The following epochs were marked as bad and are dropped:\n",
      "[]\n",
      "Channels marked as bad:\n",
      "none\n",
      "Dropped 0 epochs: \n",
      "The following epochs were marked as bad and are dropped:\n",
      "[]\n",
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "from mne import events_from_annotations, Epochs\n",
    "\n",
    "# Step 1: Convert Annotations to Events\n",
    "events, event_id = events_from_annotations(raw_eeg_data)\n",
    "print(\"Events:\", events)\n",
    "print(\"Event IDs:\", event_id)\n",
    "\n",
    "# Step 2: Define Epoch Parameters\n",
    "tmin = -0.5  # Start 0.5 seconds before the marker\n",
    "tmax = 0.0   # End at the marker time\n",
    "\n",
    "# Step 3: Create Epochs\n",
    "epochs = Epochs(raw_eeg_data, events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True)\n",
    "\n",
    "# Step 4: Visualize Epochs\n",
    "epochs.plot(scalings='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the actual experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## before recording from labrecorder, run this!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream 1:\n",
      "  Name: MarkerStream\n",
      "  Type: Markers\n",
      "  Source ID: \n",
      "  Channels: 1\n",
      "  Sampling Rate: 0.0 Hz\n",
      "\n",
      "Stream 2:\n",
      "  Name: Neuroeducation EEG\n",
      "  Type: EEG\n",
      "  Source ID: neuroEdu_JakeTear\n",
      "  Channels: 19\n",
      "  Sampling Rate: 250.0 Hz\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import json\n",
    "from pylsl import StreamInfo, StreamOutlet, resolve_stream, StreamInlet\n",
    "\n",
    "# Create the marker stream\n",
    "info = StreamInfo(name='MarkerStream', type='Markers', channel_count=1, nominal_srate=0, channel_format='string')\n",
    "outlet = StreamOutlet(info)\n",
    "\n",
    "# Find all available streams\n",
    "streams = resolve_stream()\n",
    "\n",
    "inlet = StreamInlet(streams[0])\n",
    "\n",
    "# Print details of each stream found\n",
    "for i, stream in enumerate(streams):\n",
    "    print(f\"Stream {i + 1}:\")\n",
    "    print(f\"  Name: {stream.name()}\")\n",
    "    print(f\"  Type: {stream.type()}\")\n",
    "    print(f\"  Source ID: {stream.source_id()}\")\n",
    "    print(f\"  Channels: {stream.channel_count()}\")\n",
    "    print(f\"  Sampling Rate: {stream.nominal_srate()} Hz\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## while recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent initial marker: {\"marker\": \"Marker_1\"}\n",
      "Marker: Marker_1 - Please input a number (1-10):\n",
      "Sent update tied to marker: {\"marker update\": \"Marker_1\", \"user input\": 5}\n",
      "\n",
      "Sent initial marker: {\"marker\": \"Marker_2\"}\n",
      "Marker: Marker_2 - Please input a number (1-10):\n",
      "Sent update tied to marker: {\"marker update\": \"Marker_2\", \"user input\": 10}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Momentary assessment paradigm\n",
    "try:\n",
    "    for count in range(1, 3):  # Run exactly 2 times\n",
    "        # Wait for a random interval between 15 and 20 seconds\n",
    "        interval = random.uniform(15, 20)\n",
    "        time.sleep(interval)\n",
    "\n",
    "        # Send a marker\n",
    "        marker_name = f\"Marker_{count}\"\n",
    "        metadata = json.dumps({\"marker\": marker_name})\n",
    "        outlet.push_sample([metadata])\n",
    "        print(f\"Sent initial marker: {metadata}\")\n",
    "\n",
    "        # Prompt the user for input\n",
    "        print(f\"Marker: {marker_name} - Please input a number (1-10):\")\n",
    "\n",
    "        # Validate user input\n",
    "        while True:\n",
    "            try:\n",
    "                user_input = int(input())\n",
    "                if 1 <= user_input <= 10:\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Please enter a valid number between 1 and 10.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a number between 1 and 10.\")\n",
    "\n",
    "        # Send an update tied to the original marker\n",
    "        update_metadata = json.dumps({\"marker update\": marker_name, \"user input\": user_input})\n",
    "        outlet.push_sample([update_metadata])\n",
    "        print(f\"Sent update tied to marker: {update_metadata}\\n\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Momentary assessment paradigm terminated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream Name: Neuroeducation EEG\n",
      "Stream Type: EEG\n",
      "Stream Name: MarkerStream\n",
      "Stream Type: Markers\n",
      "Markers in the Marker stream:\n",
      "  Marker: {\"marker\": \"Marker_1\"} at 1626945.09124\n",
      "  Marker: {\"marker update\": \"Marker_1\", \"user input\": 5} at 1626958.56051\n",
      "  Marker: {\"marker\": \"Marker_2\"} at 1626978.03069\n",
      "  Marker: {\"marker update\": \"Marker_2\", \"user input\": 10} at 1626986.38199\n"
     ]
    }
   ],
   "source": [
    "from pyxdf import load_xdf\n",
    "\n",
    "# Load the XDF file\n",
    "project_directory = os.path.dirname(os.path.abspath(\"EMA-anxiety-test\"))\n",
    "xdf_file = os.path.join(project_directory, \"EMAData\", \"Test2.xdf\")\n",
    "streams, header = load_xdf(xdf_file)\n",
    "\n",
    "\n",
    "# Print the streams and check for the marker stream\n",
    "for stream in streams:\n",
    "    print(f\"Stream Name: {stream['info']['name'][0]}\")\n",
    "    print(f\"Stream Type: {stream['info']['type'][0]}\")\n",
    "    if stream['info']['type'][0] == 'Markers':\n",
    "        print(\"Markers in the Marker stream:\")\n",
    "        for marker, timestamp in zip(stream['time_series'], stream['time_stamps']):\n",
    "            print(f\"  Marker: {marker[0]} at {timestamp:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-36.34058313 -44.33358008 -51.45905718 ... -69.13734062 -69.98969801\n",
      "  -69.47249653]\n",
      " [ 49.47496003  41.85663113  33.37186233 ...  13.72790945  23.4359588\n",
      "   32.65887979]\n",
      " [ 59.86079745  64.55716466  67.84205082 ...  59.60557494  53.54159915\n",
      "   46.30698767]\n",
      " ...\n",
      " [ 66.29959147  69.47453933  69.76824783 ... -50.37257558 -59.17517089\n",
      "  -65.52366096]\n",
      " [ -6.05509417   8.47647585  22.64263888 ... -28.09572595 -14.25034699\n",
      "    0.20934038]\n",
      " [-69.17816076 -65.37901798 -58.65246948 ...  69.88041726  69.17651582\n",
      "   65.3751722 ]]\n",
      "250.0\n",
      "['Fp1', 'Fp2', 'F7', 'F8', 'F3', 'F4', 'T3', 'T4', 'C3', 'C4', 'T5', 'T6', 'P3', 'P4', 'O1', 'O2', 'Fz', 'Cz', 'Pz']\n",
      "Creating RawArray with float64 data, n_channels=19, n_times=16525\n",
      "    Range : 0 ... 16524 =      0.000 ...    66.096 secs\n",
      "Ready.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x280c5830f80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 epochs: \n",
      "The following epochs were marked as bad and are dropped:\n",
      "[]\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "project_directory = os.path.dirname(os.path.abspath(\"EMA-anxiety-test\"))\n",
    "\n",
    "streams, header = pyxdf.load_xdf(os.path.join(project_directory, r\"EMAData\", r\"Test2.xdf\"))\n",
    "\n",
    "\n",
    "#raw EEG data object\n",
    "eeg_stream = next((s for s in streams if s['info']['type'][0] == 'EEG'), None)\n",
    "eeg_data = np.array(eeg_stream['time_series']).T  # Transpose to channels x samples\n",
    "sfreq = float(eeg_stream['info']['nominal_srate'][0])  # Sampling frequency\n",
    "ch_names = eeg_stream['info']['desc'][0]['channels'][0]['channel']  # Channel names\n",
    "ch_names = [ch['label'][0] for ch in ch_names]\n",
    "\n",
    "print(eeg_data)\n",
    "print(sfreq)\n",
    "print(ch_names)\n",
    "\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
    "\n",
    "raw_eeg_data = mne.io.RawArray(eeg_data, info)\n",
    "raw_eeg_data.rename_channels({ch: ch.capitalize() for ch in raw_eeg_data.ch_names})\n",
    "    # Add standard montage (10-20 system)\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "raw_eeg_data.set_montage(montage)\n",
    "\n",
    "#adding markers\n",
    "marker_stream = next(s for s in streams if s['info']['type'][0] == 'Markers')\n",
    "\n",
    "markers = [m[0] for m in marker_stream['time_series']]\n",
    "marker_timestamps = marker_stream['time_stamps']\n",
    "\n",
    "eeg_timestamps = eeg_stream['time_stamps']\n",
    "\n",
    "# Align marker timestamps with the EEG recording\n",
    "annotations = Annotations(\n",
    "    onset=marker_timestamps - eeg_timestamps[0],  # Align to EEG start time\n",
    "    duration=[0] * len(marker_timestamps),       # Markers are instantaneous\n",
    "    description=markers                          # Marker descriptions\n",
    ")\n",
    "\n",
    "# Add annotations to the Raw EEG object\n",
    "raw_eeg_data.set_annotations(annotations)\n",
    "\n",
    "raw_eeg_data.plot(title=\"raw data with markers\", scalings='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Event IDs: {'{\"marker\": \"Marker_1\"}': 1, '{\"marker\": \"Marker_2\"}': 3}\n",
      "Used Annotations descriptions: ['{\"marker\": \"Marker_1\"}', '{\"marker\": \"Marker_2\"}']\n",
      "Events: [[ 4028     0     1]\n",
      " [12263     0     3]]\n",
      "Event IDs: {'{\"marker\": \"Marker_1\"}': 1, '{\"marker\": \"Marker_2\"}': 3}\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2 events and 1001 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x280c2163c80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mne import events_from_annotations, Epochs\n",
    "\n",
    "# Step 1: Convert Annotations to Events and filter\n",
    "annotations = raw_eeg_data.annotations\n",
    "\n",
    "# Dynamically create `event_id` for all \"marker\" annotations\n",
    "event_id = {\n",
    "    desc: idx + 1\n",
    "    for idx, desc in enumerate(annotations.description)\n",
    "    if '\"marker\":' in desc\n",
    "}\n",
    "\n",
    "print(\"Dynamic Event IDs:\", event_id)\n",
    "\n",
    "\n",
    "events, event_id = events_from_annotations(raw_eeg_data, event_id = event_id)\n",
    "print(\"Events:\", events)\n",
    "print(\"Event IDs:\", event_id)\n",
    "\n",
    "#marker_event_ids = [event_id[key] for key in event_id if '\"marker\":' in key]\n",
    "#print(\"Filtered Event IDs:\", marker_event_ids)\n",
    "\n",
    "# Step 2: Define Epoch Parameters\n",
    "tmin = -4.0  # Start 4 seconds before the marker\n",
    "tmax = 0.0   # End at the marker time\n",
    "\n",
    "# Step 3: Create Epochs\n",
    "epochs = Epochs(raw_eeg_data, events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True)\n",
    "\n",
    "# Step 4: Visualize Epochs\n",
    "epochs.plot(title=\"epochs -4s to 0s (marker onset)\", scalings='auto')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the whole analysis shebang in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=19, n_times=16525\n",
      "    Range : 0 ... 16524 =      0.000 ...    66.096 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2 events and 1001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Running FOOOFGroup across 19 power spectra.\n",
      "Effective window size : 1.024 (s)\n",
      "Running FOOOFGroup across 19 power spectra.\n",
      "   Epoch Index Marker Name  User Input  Average Aperiodic Exponent\n",
      "0            0    Marker_1           5                    1.289552\n",
      "1            1    Marker_2          10                    1.289665\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mne import Annotations, events_from_annotations, Epochs\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from fooof import FOOOFGroup\n",
    "import json\n",
    "from pyxdf import load_xdf\n",
    "\n",
    "# Load the XDF file\n",
    "project_directory = os.path.dirname(os.path.abspath(\"EMA-anxiety-test\"))\n",
    "xdf_file = os.path.join(project_directory, \"EMAData\", \"Test2.xdf\")\n",
    "streams, header = load_xdf(xdf_file)\n",
    "\n",
    "# Extract EEG data stream\n",
    "eeg_stream = next((s for s in streams if s['info']['type'][0] == 'EEG'), None)\n",
    "eeg_data = np.array(eeg_stream['time_series']).T  # Transpose to channels x samples\n",
    "sfreq = float(eeg_stream['info']['nominal_srate'][0])  # Sampling frequency\n",
    "ch_names = [ch['label'][0] for ch in eeg_stream['info']['desc'][0]['channels'][0]['channel']]\n",
    "\n",
    "# Create MNE Raw object\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
    "raw_eeg_data = mne.io.RawArray(eeg_data, info)\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "raw_eeg_data.set_montage(montage)\n",
    "\n",
    "# Extract Marker Stream and Add Annotations\n",
    "marker_stream = next((s for s in streams if s['info']['type'][0] == 'Markers'), None)\n",
    "markers = [m[0] for m in marker_stream['time_series']]\n",
    "marker_timestamps = marker_stream['time_stamps']\n",
    "\n",
    "# Align markers with EEG timestamps\n",
    "eeg_timestamps = eeg_stream['time_stamps']\n",
    "annotations = Annotations(\n",
    "    onset=marker_timestamps - eeg_timestamps[0],\n",
    "    duration=[0] * len(marker_timestamps),\n",
    "    description=markers\n",
    ")\n",
    "raw_eeg_data.set_annotations(annotations)\n",
    "\n",
    "# Separate \"marker\" and \"marker update\" annotations\n",
    "initial_markers = []\n",
    "update_markers = []\n",
    "\n",
    "for desc, onset in zip(annotations.description, annotations.onset):\n",
    "    metadata = json.loads(desc)\n",
    "    if \"marker update\" in metadata:\n",
    "        update_markers.append((metadata[\"marker update\"], metadata.get(\"user input\", None), onset))\n",
    "    elif \"marker\" in metadata:\n",
    "        initial_markers.append((metadata[\"marker\"], onset))\n",
    "\n",
    "# Map initial markers to updates\n",
    "marker_mapping = {name: user_input for name, user_input, _ in update_markers}\n",
    "\n",
    "# Filter only initial markers that have a corresponding update\n",
    "filtered_events = [\n",
    "    [int(onset * raw_eeg_data.info['sfreq']), 0, idx + 1]\n",
    "    for idx, (name, onset) in enumerate(initial_markers)\n",
    "    if name in marker_mapping\n",
    "]\n",
    "\n",
    "# Create event ID dynamically\n",
    "event_id = {name: idx + 1 for idx, (name, _) in enumerate(initial_markers) if name in marker_mapping}\n",
    "\n",
    "# Convert filtered events to MNE Events\n",
    "events = np.array(filtered_events)\n",
    "\n",
    "# Create Epochs\n",
    "tmin, tmax = -4.0, 0.0  # Define epoch time window\n",
    "epochs = Epochs(raw_eeg_data, events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True)\n",
    "\n",
    "# Process each epoch to calculate aperiodic exponent and map to user input\n",
    "results = []\n",
    "\n",
    "for epoch_idx, (epoch, event) in enumerate(zip(epochs.get_data(), epochs.events)):\n",
    "    try:\n",
    "        # Compute PSD\n",
    "        psd, freqs = psd_array_welch(epoch, fmin=1, fmax=50, sfreq=epochs.info['sfreq'], average='mean')\n",
    "\n",
    "        # Fit FOOOFGroup to extract aperiodic exponents\n",
    "        fg = FOOOFGroup(peak_width_limits=(2, 8))\n",
    "        fg.fit(freqs, psd)\n",
    "        aperiodic_exponents = [aperiodic_params[1] for aperiodic_params in fg.get_params('aperiodic_params')]\n",
    "        avg_aperiodic_exponent = np.mean(aperiodic_exponents)\n",
    "\n",
    "        # Match the marker name to its user input\n",
    "        event_marker = list(event_id.keys())[list(event_id.values()).index(event[2])]\n",
    "        user_input = marker_mapping.get(event_marker, None)\n",
    "\n",
    "        # Append results\n",
    "        results.append({\n",
    "            \"Epoch Index\": epoch_idx,\n",
    "            \"Marker Name\": event_marker,\n",
    "            \"User Input\": user_input,\n",
    "            \"Average Aperiodic Exponent\": avg_aperiodic_exponent\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing epoch {epoch_idx}: {e}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Display or save the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This does it but based on when the user actually presses enter instead of the initial marker send."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16525, 19)\n",
      "Creating RawArray with float64 data, n_channels=19, n_times=16525\n",
      "    Range : 0 ... 16524 =      0.000 ...    66.096 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2 events and 1001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Running FOOOFGroup across 19 power spectra.\n",
      "Effective window size : 1.024 (s)\n",
      "Running FOOOFGroup across 19 power spectra.\n",
      "   Epoch Index Marker Name  User Input  Average Aperiodic Exponent\n",
      "0            0    Marker_1           5                    1.349396\n",
      "1            1    Marker_2          10                    1.346805\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mne import Annotations, events_from_annotations, Epochs\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from fooof import FOOOFGroup\n",
    "import json\n",
    "from pyxdf import load_xdf\n",
    "\n",
    "# Load the XDF file\n",
    "project_directory = os.path.dirname(os.path.abspath(\"EMA-anxiety-test\"))\n",
    "xdf_file = os.path.join(project_directory, \"EMAData\", \"Test2.xdf\")\n",
    "streams, header = load_xdf(xdf_file)\n",
    "\n",
    "# Extract EEG data stream\n",
    "eeg_stream = next((s for s in streams if s['info']['type'][0] == 'EEG'), None)\n",
    "#print((np.array(eeg_stream['time_series']).shape))\n",
    "eeg_data = np.array(eeg_stream['time_series']).T  # Transpose to channels x samples\n",
    "sfreq = float(eeg_stream['info']['nominal_srate'][0])  # Sampling frequency\n",
    "ch_names = [ch['label'][0] for ch in eeg_stream['info']['desc'][0]['channels'][0]['channel']]\n",
    "\n",
    "# Create MNE Raw object\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
    "raw_eeg_data = mne.io.RawArray(eeg_data, info)\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "raw_eeg_data.set_montage(montage)\n",
    "\n",
    "# Extract Marker Stream and Add Annotations\n",
    "marker_stream = next((s for s in streams if s['info']['type'][0] == 'Markers'), None)\n",
    "markers = [m[0] for m in marker_stream['time_series']]\n",
    "marker_timestamps = marker_stream['time_stamps']\n",
    "\n",
    "# Align markers with EEG timestamps\n",
    "eeg_timestamps = eeg_stream['time_stamps']\n",
    "annotations = Annotations(\n",
    "    onset=marker_timestamps - eeg_timestamps[0],\n",
    "    duration=[0] * len(marker_timestamps),\n",
    "    description=markers\n",
    ")\n",
    "raw_eeg_data.set_annotations(annotations)\n",
    "\n",
    "# Filter only \"marker update\" annotations\n",
    "update_markers = []\n",
    "\n",
    "for desc, onset in zip(annotations.description, annotations.onset):\n",
    "    metadata = json.loads(desc)\n",
    "    if \"marker update\" in metadata:\n",
    "        update_markers.append((metadata[\"marker update\"], metadata.get(\"user input\", None), onset))\n",
    "\n",
    "# Create events based on \"marker update\" annotations\n",
    "event_id = {name: idx + 1 for idx, (name, _, _) in enumerate(update_markers)}\n",
    "filtered_events = [\n",
    "    [int(onset * raw_eeg_data.info['sfreq']), 0, event_id[name]]\n",
    "    for name, _, onset in update_markers\n",
    "]\n",
    "\n",
    "# Convert filtered events to MNE Events\n",
    "events = np.array(filtered_events)\n",
    "\n",
    "# Create Epochs\n",
    "tmin, tmax = -4.0, 0.0  # Define epoch time window\n",
    "epochs = Epochs(raw_eeg_data, events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True)\n",
    "\n",
    "# Process each epoch to calculate aperiodic exponent and map to user input\n",
    "results = []\n",
    "\n",
    "for epoch_idx, (epoch, event) in enumerate(zip(epochs.get_data(), epochs.events)):\n",
    "    try:\n",
    "        # Compute PSD\n",
    "        psd, freqs = psd_array_welch(epoch, fmin=1, fmax=50, sfreq=epochs.info['sfreq'], average='mean')\n",
    "\n",
    "        # Fit FOOOFGroup to extract aperiodic exponents\n",
    "        fg = FOOOFGroup(peak_width_limits=(2, 8))\n",
    "        fg.fit(freqs, psd)\n",
    "        aperiodic_exponents = [aperiodic_params[1] for aperiodic_params in fg.get_params('aperiodic_params')]\n",
    "        avg_aperiodic_exponent = np.mean(aperiodic_exponents)\n",
    "\n",
    "        # Match the marker name to its user input\n",
    "        event_marker = list(event_id.keys())[list(event_id.values()).index(event[2])]\n",
    "        user_input = next(\n",
    "            (input_value for name, input_value, _ in update_markers if name == event_marker),\n",
    "            None\n",
    "        )\n",
    "\n",
    "        # Append results\n",
    "        results.append({\n",
    "            \"Epoch Index\": epoch_idx,\n",
    "            \"Marker Name\": event_marker,\n",
    "            \"User Input\": user_input,\n",
    "            \"Average Aperiodic Exponent\": avg_aperiodic_exponent\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing epoch {epoch_idx}: {e}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Display or save the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a test of scaling this analysis up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Test2.xdf for subject: Test2\n",
      "Creating RawArray with float64 data, n_channels=19, n_times=16525\n",
      "    Range : 0 ... 16524 =      0.000 ...    66.096 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2 events and 1001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Running FOOOFGroup across 19 power spectra.\n",
      "Effective window size : 1.024 (s)\n",
      "Running FOOOFGroup across 19 power spectra.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Epoch Index</th>\n",
       "      <th>Marker Name</th>\n",
       "      <th>Anxiety Rating</th>\n",
       "      <th>Average Aperiodic Exponent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test2</td>\n",
       "      <td>0</td>\n",
       "      <td>Marker_1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.349396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test2</td>\n",
       "      <td>1</td>\n",
       "      <td>Marker_2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.346805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject ID  Epoch Index Marker Name  Anxiety Rating  \\\n",
       "0      Test2            0    Marker_1               5   \n",
       "1      Test2            1    Marker_2              10   \n",
       "\n",
       "   Average Aperiodic Exponent  \n",
       "0                    1.349396  \n",
       "1                    1.346805  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mne import Annotations, events_from_annotations, Epochs\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from fooof import FOOOFGroup\n",
    "import json\n",
    "from pyxdf import load_xdf\n",
    "\n",
    "# Directory containing the .xdf files\n",
    "project_directory = os.path.dirname(os.path.abspath(\"EMA-anxiety-test\"))\n",
    "data_directory = os.path.join(project_directory, \"EMAData\")\n",
    "\n",
    "# Create a list of all .xdf files in the directory\n",
    "xdf_files = [f for f in os.listdir(data_directory) if f.endswith(\".xdf\")]\n",
    "\n",
    "# Initialize a list to store results for all subjects\n",
    "all_subjects_results = []\n",
    "\n",
    "# Process each .xdf file\n",
    "for xdf_file in xdf_files:\n",
    "    # Extract the subject ID from the filename\n",
    "    subject_id = os.path.splitext(xdf_file)[0]\n",
    "\n",
    "    print(f\"Processing file: {xdf_file} for subject: {subject_id}\")\n",
    "\n",
    "    # Load the XDF file\n",
    "    streams, header = load_xdf(os.path.join(data_directory, xdf_file))\n",
    "\n",
    "    # Extract EEG data stream\n",
    "    eeg_stream = next((s for s in streams if s['info']['type'][0] == 'EEG'), None)\n",
    "    eeg_data = np.array(eeg_stream['time_series']).T  # Transpose to channels x samples\n",
    "    sfreq = float(eeg_stream['info']['nominal_srate'][0])  # Sampling frequency\n",
    "    ch_names = [ch['label'][0] for ch in eeg_stream['info']['desc'][0]['channels'][0]['channel']]\n",
    "\n",
    "    # Create MNE Raw object\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
    "    raw_eeg_data = mne.io.RawArray(eeg_data, info)\n",
    "    montage = mne.channels.make_standard_montage('standard_1020')\n",
    "    raw_eeg_data.set_montage(montage)\n",
    "\n",
    "    # Extract Marker Stream and Annotations\n",
    "    marker_stream = next((s for s in streams if s['info']['type'][0] == 'Markers'), None)\n",
    "    markers = [m[0] for m in marker_stream['time_series']]\n",
    "    marker_timestamps = marker_stream['time_stamps']\n",
    "    eeg_timestamps = eeg_stream['time_stamps']\n",
    "\n",
    "    annotations = Annotations(\n",
    "        onset=marker_timestamps - eeg_timestamps[0],\n",
    "        duration=[0] * len(marker_timestamps),\n",
    "        description=markers\n",
    "    )\n",
    "    raw_eeg_data.set_annotations(annotations)\n",
    "\n",
    "    # Filter only \"marker update\" annotations\n",
    "    update_markers = [\n",
    "        (json.loads(desc).get(\"marker update\"), json.loads(desc).get(\"user input\"), onset)\n",
    "        for desc, onset in zip(annotations.description, annotations.onset)\n",
    "        if \"marker update\" in json.loads(desc)\n",
    "    ]\n",
    "\n",
    "    # Create events based on \"marker update\" annotations\n",
    "    event_id = {name: idx + 1 for idx, (name, _, _) in enumerate(update_markers)}\n",
    "    filtered_events = [\n",
    "        [int(onset * raw_eeg_data.info['sfreq']), 0, event_id[name]]\n",
    "        for name, _, onset in update_markers\n",
    "    ]\n",
    "    events = np.array(filtered_events)\n",
    "\n",
    "    # Create Epochs\n",
    "    tmin, tmax = -4.0, 0.0  # Define epoch time window\n",
    "    epochs = Epochs(raw_eeg_data, events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True)\n",
    "\n",
    "    # Process each epoch to calculate aperiodic exponent and map to user input\n",
    "    subject_results = []\n",
    "    for epoch_idx, (epoch, event) in enumerate(zip(epochs.get_data(), epochs.events)):\n",
    "        try:\n",
    "            # Compute PSD\n",
    "            psd, freqs = psd_array_welch(epoch, fmin=1, fmax=50, sfreq=epochs.info['sfreq'], average='mean')\n",
    "\n",
    "            # Fit FOOOFGroup to extract aperiodic exponents\n",
    "            fg = FOOOFGroup(peak_width_limits=(2, 8))\n",
    "            fg.fit(freqs, psd)\n",
    "            aperiodic_exponents = [aperiodic_params[1] for aperiodic_params in fg.get_params('aperiodic_params')]\n",
    "            avg_aperiodic_exponent = np.mean(aperiodic_exponents)\n",
    "\n",
    "            # Match the marker name to its user input\n",
    "            event_marker = list(event_id.keys())[list(event_id.values()).index(event[2])]\n",
    "            user_input = next(\n",
    "                (input_value for name, input_value, _ in update_markers if name == event_marker),\n",
    "                None\n",
    "            )\n",
    "\n",
    "            # Append results for this epoch\n",
    "            subject_results.append({\n",
    "                \"Subject ID\": subject_id,\n",
    "                \"Epoch Index\": epoch_idx,\n",
    "                \"Marker Name\": event_marker,\n",
    "                \"Anxiety Rating\": user_input,\n",
    "                \"Average Aperiodic Exponent\": avg_aperiodic_exponent\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing epoch {epoch_idx} for subject {subject_id}: {e}\")\n",
    "\n",
    "    # Save subject's results to all results\n",
    "    all_subjects_results.extend(subject_results)\n",
    "\n",
    "    # Optionally save individual subject results to a CSV\n",
    "    subject_df = pd.DataFrame(subject_results)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "all_results_df = pd.DataFrame(all_subjects_results)\n",
    "\n",
    "# Display the combined results\n",
    "all_results_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
